#What is Airflow?

The formal definition is as follows:

*"Apache Airflow is an open source platform to ***programmatically author, schedule*** and ***monitor*** workflows."*

Or similarly:

*Airflow is an orchestrator allowing you to execute your tasks at the right time, in the right way, in the right order.*

Airflow allows you to create data pipelines that will interact with many different tools, such as in our use case in section 1.1).

###What are the benefits to Airflow?

* Data pipelines we create are **dynamic** - Airflow primarily uses Python, so all of the added functionality of Python is also available when constructing these pipelines.
* **Scalability** - Airflow is really scalable, you can execute many tasks in parallel depending on your architecture & resources. *(This is where things like Kubernetes clusters come into play).*
* Airflow has a very friendly **User Interface** - We can monitor data pipelines, retry tasks etc.
* It is **extensible** - Meaning that if there is a new tool or piece of software you need to interact with, you don't need to wait for Airflow to be upgraded. We can instead create our own **plug-in**.

###What are the key components of Airflow?

1). Web server\
2). Scheduler - Daemon in charge of scheduling workflows.\
3). Metastore - Database where metadata are stored (usually PostgreSQL). \
4). Executor - Class defining how tasks are executed (e.g. Kubernetes executor, local executor).
5). Worker - Where the task is executed.

###Important concepts.

**DAG** - Directed acyclic graph. A graph with derogated edges and no loops.

Node 1 **----->** Node 2 **----->** Node 3

Here, Node 3 depends on Node 2, Node 2 on Node 1 etc.

**Operator** - A wrapper around the task we want to do.

* Action Operators - Operators executing functions or commands. i.e. the bash operator executes bash commands, python operator executes python commands & functions etc.
* Transfer Operators - These allow you to transfer data between sources and to the destination.
* Sensor Operators - These wait for something to happen before moving to the next task, i.e. waiting for a file to drop.

**Task Instance** - Executable operators & tasks once active become Task Instances.

**Workflow** - A combination of all of the above.

###What isn't Airflow?

*"Airflow is not a data streaming solution nor is it a data processing framework."*